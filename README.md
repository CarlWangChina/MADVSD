# MADVSD: Multi-Accent Mandarin Dry-Vocal Singing Dataset

**[Paper] Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition** *Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)*

[![arXiv](https://img.shields.io/badge/arXiv-2512.07005-b31b1b.svg)](https://www.arxiv.org/abs/2512.07005)
[![ACM DL](https://img.shields.io/badge/ACM%20DL-10.1145%2F3746027.3758210-blue)](https://dl.acm.org/doi/10.1145/3746027.3758210)

---

## ğŸ—ºï¸ Regional Distribution Visualization

For readers interested in a visual reference regarding the dataset's geographical coverage, we provide the high-resolution visualization of the speaker distribution below. This map color-codes the geography into nine distinct regions to visualize the speaker distribution across China.

![Figure_Regional_Distribution_01](https://github.com/user-attachments/assets/20855b87-4602-468c-89b0-83caf3991d3f)


> **Regional Accent Distribution, Speaker Demographics, and Recording Content of the MADVSD Dataset.**
>
> * **Gray Areas:** Indicate regions not included in this study due to limitations in data collection. Collaboration with our **nationwide partner** was constrained by their **operational network coverage**, hindering data acquisition from all provinces. Future endeavors will explore alternative strategies to incorporate data from these uncovered regions.
> * **Extended Regional Scope (e.g., SGXR):** Reflects a balance between accent type granularity and speaker representation per type, optimized for model training efficacy. While recordings spanned every province/city, accent region demarcation prioritized sufficient speaker counts per category while maintaining a manageable number of accent types (under ten) for the accent identification task. Consequently, geographically smaller accent regions are defined in eastern coastal areas with a higher speaker count, whereas larger regions correspond to the central and western areas with a lower speaker count. Future data enrichment is expected to facilitate a more refined and geographically precise categorization of accent types and regions.

---

## ğŸ“– Introduction

Singing accent research is underexplored compared to speech accent studies, primarily due to the scarcity of suitable datasets. Existing singing datasets often suffer from detail loss (resulting from vocal-instrumental separation) or lack regional accent annotations.

To address this, we introduce **MADVSD** (Multi-Accent Mandarin Dry-Vocal Singing Dataset). MADVSD comprises over **670 hours** of dry vocal recordings from **4,206 native Mandarin speakers** across nine distinct Chinese regions.

### Key Features
* **Scale:** 12,618 full-length a cappella song performances.
* **Content:** Each participant recorded audio of three popular songs in their native accent, plus phonetic exercises covering all Mandarin vowels and a full octave range.
* **Demographics:** 4,206 participants from diverse regions (SZR, JR, SSHR, BMLR, SGXR, FR, HHAR, GGR, YGSR).
* **Quality:** Dry vocals recorded in quiet environments, processed for noise reduction and dereverberation.

---

## ğŸ“‚ Repository Structure & Resources

In addition to the dataset information, we provide the following resources in this repository to assist researchers in understanding our data collection protocols:

* **`Figure_Regional_Distribution.pdf`**: The high-resolution version of the speaker regional distribution map.
* **`samples/`**: A folder containing audio samples.
* **`Protocol_Phonetic_Exercises_EN.docx` / `_CN.docx`**: The standardized "vowels and scales" recording instructions distributed to participants (available in English and Chinese).
* **`Recording_Guidelines_and_Standards.docx`**: Detailed technical requirements and content standards for the recording materials.
* **`Statistics_Recording_Center_Distribution.pdf` / `.xlsx`**: Detailed statistics on the quantity and distribution of regional recording centers participating in the data collection.

---

## ğŸ”’ Data Availability & Privacy Statement

### Current Access Status
Due to stringent privacy and ethical considerations, **the full MADVSD dataset is not currently open for public download.**

### Ethical Context
While we are strong advocates for open science and community sharing, we must balance research advancement with the protection of human subjects. The MADVSD raw audio contains **non-redactable Personally Identifiable Information (PII)**. Specifically, participants state their real names and specific hometowns within the recordings.

Releasing this data publicly poses significant risks, including:
1.  **Privacy Violation:** The combination of voice biometrics, names, and location data is sensitive.
2.  **Potential for Misuse:** High-quality voice data paired with identity verification can be exploited for malicious purposes, such as deepfakes or telecommunications fraud.

We are currently undergoing legal review to explore licensing frameworks that might allow for controlled access in the future. We appreciate your patience and understanding as we prioritize the safety and rights of our participants.

### Samples and Verification
To demonstrate the quality and existence of the dataset, we have provided:

1.  **Sample Audio:** A small set of 4 audio files from **2 representative speakers** (one Male from Henan, one Female from Beijing) can be found in the `samples/` folder. These include both song performances and phonetic exercises.
2.  **Dataset Structure:** Below is a screenshot of the full dataset directory (hosted on private storage), demonstrating the scale of the data collected.

<img width="956" height="1066" alt="ScreenShot_2026-01-04_150236_959" src="https://github.com/user-attachments/assets/92c258fb-e6c5-443b-ac01-0ded571c45df" />
<img width="968" height="922" alt="ScreenShot_2026-01-04_150244_350" src="https://github.com/user-attachments/assets/9737c2ef-4544-4428-9ae4-e309b2b33a00" />
<img width="982" height="1072" alt="ScreenShot_2026-01-04_150303_473" src="https://github.com/user-attachments/assets/98544c75-6177-44e6-9621-86aa0a90c13a" />
<img width="1732" height="980" alt="ScreenShot_2026-01-04_150609_931" src="https://github.com/user-attachments/assets/02be5a54-e157-4239-8478-6b6663509758" />
<img width="1124" height="1572" alt="ScreenShot_2026-01-04_150407_043" src="https://github.com/user-attachments/assets/e6830e2f-591e-448e-a99f-a26037a0bc39" />
<img width="1356" height="1322" alt="ScreenShot_2026-01-04_150511_220" src="https://github.com/user-attachments/assets/47e62d0f-5f42-4c2d-8479-62413945ee64" />

### Samples and Verification
To demonstrate the quality and existence of the dataset, we have provided:

1. Â **Sample Audio:** A small set of 4 audio files from **2 representative speakers** (one Male from Henan, one Female from Beijing) can be found in the `samples/` folder. These include both song performances and phonetic exercises.
2. Â **Dataset Structure:** Below is a screenshot of the full dataset directory (hosted on private storage), demonstrating the scale of the data collected.

<div align="center">
  <img src="https://github.com/user-attachments/assets/92c258fb-e6c5-443b-ac01-0ded571c45df" width="30%" />
  <img src="https://github.com/user-attachments/assets/9737c2ef-4544-4428-9ae4-e309b2b33a00" width="30%" />
  <img src="https://github.com/user-attachments/assets/98544c75-6177-44e6-9621-86aa0a90c13a" width="30%" />
  <img src="https://github.com/user-attachments/assets/02be5a54-e157-4239-8478-6b6663509758" width="30%" />
  <img src="https://github.com/user-attachments/assets/e6830e2f-591e-448e-a99f-a26037a0bc39" width="30%" />
  <img src="https://github.com/user-attachments/assets/47e62d0f-5f42-4c2d-8479-62413945ee64" width="30%" />
</div>

### Recommended Alternatives
* **For Singing Evaluation:** If you are working on singing voice assessment or related tasks, we recommend checking our related project: [**QwenFeat-Vocal-Score**](https://github.com/CarlWangChina/QwenFeat-Vocal-Score).
* **For Other Singing Data:** Please refer to our sister project **VocalVerse** (details forthcoming) for open-source singing resources.

---

## ğŸ“ Citation

If you reference this work or the concepts presented, please cite our paper:

**ACM Reference Format:**
> Zihao Wang, Shulei Ji, Le Ma, Yuhang Jin, Shun Lei, Jianyi Chen, Haoying Fu, Roger B. Dannenberg, and Kejun Zhang. 2025. Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition. In *Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)*. Association for Computing Machinery, New York, NY, USA, 12714â€“12721. https://doi.org/10.1145/3746027.3758210.

**BibTeX:**

```bibtex
@inproceedings{10.1145/3746027.3758210,
   author = {Wang, Zihao and Ji, Shulei and Ma, Le and Jin, Yuhang and Lei, Shun and Chen, Jianyi and Fu, Haoying and Dannenberg, Roger B. and Zhang, Kejun},
   title = {Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition},
   year = {2025},
   isbn = {9798400720352},
   publisher = {Association for Computing Machinery},
   address = {New York, NY, USA},
   url = {https://doi.org/10.1145/3746027.3758210},
   doi = {10.1145/3746027.3758210},
   booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
   pages = {12714â€“12721},
   numpages = {8},
   keywords = {dry vocals, mandarin singing dataset, regional chinese accents, singing accent recognition},
   location = {Dublin, Ireland},
   series = {MM '25}
}
```

# MADVSD: å¤šå£éŸ³æ™®é€šè¯å¹²å£°æ¸…å”±æ•°æ®é›†

**[è®ºæ–‡] Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition** *Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)*

---

## ğŸ—ºï¸ åŒºåŸŸåˆ†å¸ƒå¯è§†åŒ–

ä¸ºäº†ç»™è¯»è€…æä¾›ç›´è§‚çš„å‚è€ƒï¼Œæˆ‘ä»¬åœ¨æœ¬é¡¹ç›®ä»“åº“ä¸­å±•ç¤ºäº†æ•°æ®é›†çš„è¯´è¯äººåœ°ç†åˆ†å¸ƒå›¾ã€‚æˆ‘ä»¬åœ¨è®ºæ–‡æ­£æ–‡ä¸­å¹¶æœªåŒ…å«æ­¤å›¾ï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹æŸ¥çœ‹é«˜æ¸…ç‰ˆæœ¬ã€‚è¯¥åœ°å›¾é€šè¿‡é¢œè‰²ç¼–ç å°†ä¸­å›½åœ°ç†åˆ’åˆ†ä¸ºä¹ä¸ªä¸åŒçš„å£éŸ³åŒºåŸŸï¼Œä»¥å¯è§†åŒ–è¯´è¯äººçš„åˆ†å¸ƒæƒ…å†µã€‚

![Figure_Regional_Distribution_01](https://github.com/user-attachments/assets/20855b87-4602-468c-89b0-83caf3991d3f)

> **MADVSDæ•°æ®é›†çš„åŒºåŸŸå£éŸ³åˆ†å¸ƒã€è¯´è¯äººç»Ÿè®¡åŠå½•éŸ³å†…å®¹**
>
> * **ç°è‰²åŒºåŸŸï¼š** è¡¨ç¤ºç”±äºæ•°æ®é‡‡é›†é™åˆ¶ï¼Œæœ¬æ¬¡ç ”ç©¶æœªåŒ…å«çš„åŒºåŸŸã€‚æˆ‘ä»¬ä¸**æŸå…¨å›½æ€§è¿é”æœºæ„**åˆä½œè®¾ç«‹å½•éŸ³ä¸­å¿ƒï¼Œä½†å—é™äºå…¶**è¿è¥ç½‘ç»œè¦†ç›–èŒƒå›´**ï¼Œæ— æ³•è¦†ç›–æ‰€æœ‰çœä»½ã€‚æœªæ¥æˆ‘ä»¬å°†æ¢ç´¢å…¶ä»–ç­–ç•¥ä»¥è¡¥å……è¿™äº›æœªè¦†ç›–åŒºåŸŸçš„æ•°æ®ã€‚
> * **æ‰©å±•çš„åŒºåŸŸèŒƒå›´ï¼ˆå¦‚SGXRï¼‰ï¼š** åæ˜ äº†å£éŸ³ç±»å‹ç²’åº¦ä¸æ¯ç§ç±»å‹è¯´è¯äººä»£è¡¨æ€§ä¹‹é—´çš„å¹³è¡¡ï¼Œæ—¨åœ¨ä¼˜åŒ–æ¨¡å‹è®­ç»ƒæ•ˆæœã€‚è™½ç„¶æˆ‘ä»¬çš„å½•éŸ³è¦†ç›–äº†æ¯ä¸ªçœ/å¸‚ï¼Œä½†åœ¨åˆ’å®šå£éŸ³åŒºåŸŸæ—¶ï¼Œæˆ‘ä»¬ä¼˜å…ˆè€ƒè™‘ç¡®ä¿æ¯ä¸ªç±»åˆ«æœ‰è¶³å¤Ÿçš„è¯´è¯äººæ•°é‡ï¼ŒåŒæ—¶å°†å£éŸ³ç±»å‹ä¿æŒåœ¨å¯ç®¡ç†çš„æ•°é‡ï¼ˆ10ä¸ªä»¥å†…ï¼‰ï¼Œä»¥ä¾¿äºå£éŸ³è¯†åˆ«ä»»åŠ¡ã€‚å› æ­¤ï¼Œè¯´è¯äººå¯†é›†çš„ä¸œéƒ¨æ²¿æµ·åœ°åŒºè¢«åˆ’åˆ†ä¸ºåœ°ç†èŒƒå›´è¾ƒå°çš„å£éŸ³åŒºï¼Œè€Œè¯´è¯äººè¾ƒå°‘çš„ä¸­è¥¿éƒ¨åœ°åŒºåˆ™å¯¹åº”è¾ƒå¤§çš„åœ°ç†èŒƒå›´ã€‚éšç€æœªæ¥æ•°æ®çš„ä¸°å¯Œï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥ç»†åŒ–å£éŸ³ç±»å‹å’ŒåŒºåŸŸçš„åˆ’åˆ†ã€‚

---

## ğŸ“– ç®€ä»‹

ç›¸æ¯”äºè¯­éŸ³å£éŸ³ç ”ç©¶ï¼Œæ­Œå”±å£éŸ³çš„ç ”ç©¶å°šå¤„äºèµ·æ­¥é˜¶æ®µï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹åˆé€‚çš„æ•°æ®é›†ã€‚ç°æœ‰çš„æ­Œå”±æ•°æ®é›†å¾€å¾€å› ä¼´å¥åˆ†ç¦»è¿‡ç¨‹å¯¼è‡´ç»†èŠ‚ä¸¢å¤±ï¼Œä¸”é€šå¸¸ç¼ºä¹åŒºåŸŸå£éŸ³çš„æ ‡æ³¨ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº† **MADVSD**ï¼ˆå¤šå£éŸ³æ™®é€šè¯å¹²å£°æ¸…å”±æ•°æ®é›†ï¼‰ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªä¸­å›½ä¹ä¸ªä¸åŒåŒºåŸŸçš„ **4,206å** æ¯è¯­ä¸ºæ™®é€šè¯çš„è¯´è¯äººå½•åˆ¶çš„è¶…è¿‡ **670å°æ—¶** çš„å¹²å£°æ¸…å”±å½•éŸ³ã€‚

### ä¸»è¦ç‰¹ç‚¹
* **è§„æ¨¡ï¼š** 12,618 é¦–å®Œæ•´çš„æ— ä¼´å¥æ¸…å”±æ­Œæ›²ã€‚
* **å†…å®¹ï¼š** æ¯ä½å‚ä¸è€…ç”¨å®¶ä¹¡å£éŸ³å½•åˆ¶äº†ä¸‰é¦–æµè¡Œæ­Œæ›²ï¼Œä»¥åŠæ¶µç›–æ‰€æœ‰æ™®é€šè¯å…ƒéŸ³å’Œå…¨å…«åº¦éŸ³é˜¶çš„è¯­éŸ³ç»ƒä¹ ã€‚
* **ç¾¤ä½“ï¼š** 4,206 åå‚ä¸è€…ï¼Œè¦†ç›–å¹¿æ³›çš„åœ°ç†åŒºåŸŸã€‚
* **è´¨é‡ï¼š** åœ¨å®‰é™ç¯å¢ƒä¸‹å½•åˆ¶çš„å¹²å£°ï¼Œå¹¶ç»è¿‡é™å™ªå’Œå»æ··å“å¤„ç†ã€‚

---

## ğŸ“‚ ä»“åº“æ–‡ä»¶ç»“æ„ä¸èµ„æº

é™¤äº†æ•°æ®é›†ä»‹ç»å¤–ï¼Œæˆ‘ä»¬åœ¨æœ¬ä»“åº“ä¸­è¿˜æä¾›äº†ä»¥ä¸‹æ–‡ä»¶ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜äº†è§£æˆ‘ä»¬çš„æ•°æ®é‡‡é›†æ ‡å‡†ï¼š
* **`Figure_Regional_Distribution.pdf`**ï¼šè¯´è¯äººåŒºåŸŸåˆ†å¸ƒåœ°å›¾çš„é«˜æ¸…ç‰ˆã€‚
* * **`samples/`**ï¼šåŒ…å«éŸ³é¢‘æ ·æœ¬çš„æ–‡ä»¶å¤¹ã€‚
* **`Protocol_Phonetic_Exercises_EN.docx` / `_CN.docx`**ï¼šå‘æ”¾ç»™å‚ä¸è€…çš„æ ‡å‡†åŒ–â€œå…ƒéŸ³ä¸éŸ³é˜¶â€å½•éŸ³æŒ‡å¯¼æ‰‹å†Œï¼ˆå«ä¸­è‹±æ–‡ç‰ˆï¼‰ã€‚
* **`Recording_Guidelines_and_Standards.docx`**ï¼šå½•éŸ³ç´ æçš„è¯¦ç»†æŠ€æœ¯è¦æ±‚ä¸æ¼”å”±å†…å®¹æ ‡å‡†ã€‚
* **`Statistics_Recording_Center_Distribution.pdf` / `.xlsx`**: å‚ä¸æœ¬æ¬¡æ•°æ®é‡‡é›†çš„å„åŒºåŸŸå½•éŸ³ä¸­å¿ƒæ•°é‡ä¸åˆ†å¸ƒçš„è¯¦ç»†ç»Ÿè®¡æ•°æ®ã€‚
---

## ğŸ”’ æ•°æ®å¯ç”¨æ€§ä¸éšç§å£°æ˜

### å½“å‰å¼€æ”¾çŠ¶æ€
å‡ºäºå¯¹ç”¨æˆ·éšç§å’Œé“å¾·ä¼¦ç†çš„è€ƒé‡ï¼Œ**MADVSD å®Œæ•´æ•°æ®é›†ç›®å‰æš‚ä¸æä¾›å…¬å¼€ä¸‹è½½ã€‚**

### éšç§ä¿æŠ¤ä¸ä¼¦ç†è€ƒé‡
è™½ç„¶æˆ‘ä»¬è‡´åŠ›äºæ¨åŠ¨äººå·¥æ™ºèƒ½ç¤¾åŒºçš„å¼€æºä¸åˆ†äº«ï¼Œä½†æˆ‘ä»¬å¿…é¡»åœ¨å¼€æ”¾ç ”ç©¶ä¸å—è¯•è€…çš„äººæƒè´£ä»»ä¹‹é—´å–å¾—å¹³è¡¡ã€‚MADVSD çš„åŸå§‹éŸ³é¢‘åŒ…å«**æ— æ³•å®Œå…¨è„±æ•çš„ä¸ªäººèº«ä»½ä¿¡æ¯ (PII)**ã€‚å…·ä½“è€Œè¨€ï¼Œå½•éŸ³ä¸­åŒ…å«æ¯ä½å‚ä¸è€…è‡ªè¿°çš„çœŸå®å§“åå’Œå…·ä½“å®¶ä¹¡ä½ç½®ã€‚

å…¬å¼€è¿™äº›æ•°æ®å­˜åœ¨æ˜¾è‘—çš„é£é™©ï¼š
1.  **éšç§æ³„éœ²ï¼š** ç”¨æˆ·çš„å£°çº¹ç‰¹å¾ä¸å§“åã€ä½ç½®ä¿¡æ¯çš„ç»“åˆå±äºé«˜åº¦æ•æ„Ÿæ•°æ®ã€‚
2.  **æ»¥ç”¨é£é™©ï¼š** è¿™äº›æ•°æ®ææ˜“è¢«ç”¨äºè®­ç»ƒæ·±åº¦ä¼ªé€ ï¼ˆDeepfakeï¼‰æ¨¡å‹ï¼Œè¿›è€Œå¯èƒ½è¢«ç”¨äº AI ç”µä¿¡è¯ˆéª—æˆ–å…¶ä»–çŠ¯ç½ªæ´»åŠ¨ã€‚

ç›®å‰ï¼Œæˆ‘ä»¬æ­£åœ¨å¤„ç†ç›¸å…³çš„éŸ³è‰²æˆæƒåˆåŒä¸æ³•å¾‹åˆè§„å®¡æŸ¥ã€‚è¯·è€å¿ƒç­‰å¾…ï¼Œæˆ‘ä»¬ä¼šåœ¨ç¡®ä¿å®‰å…¨çš„å‰æä¸‹æ¢ç´¢æœªæ¥çš„å¼€æ”¾å½¢å¼ã€‚

### æ ·æœ¬ä¸éªŒè¯
ä¸ºäº†è¯æ˜æ•°æ®é›†çš„è´¨é‡å’ŒçœŸå®æ€§ï¼Œæˆ‘ä»¬æä¾›äº†ä»¥ä¸‹å†…å®¹ï¼š

1.  **éŸ³é¢‘æ ·æœ¬ï¼š** `samples/` æ–‡ä»¶å¤¹ä¸­åŒ…å«æ¥è‡ª **2ä½ä»£è¡¨æ€§è¯´è¯äºº**ï¼ˆä¸€ä½æ²³å—ç”·æ€§ï¼Œä¸€ä½åŒ—äº¬å¥³æ€§ï¼‰çš„å…± **4ä¸ªéŸ³é¢‘æ–‡ä»¶**ã€‚æ ·æœ¬åŒ…å«æ­Œæ›²æ¸…å”±å’ŒéŸ³é˜¶ç»ƒä¹ ä¸¤ç§ç±»å‹ã€‚
2.  **æ•°æ®è§„æ¨¡æ¦‚è§ˆï¼š** ä¸‹å›¾å±•ç¤ºäº†å­˜å‚¨åœ¨ç§æœ‰äº‘ç«¯çš„æ•°æ®é›†å®Œæ•´ç›®å½•ç»“æ„æˆªå›¾ï¼ˆå·²å¯¹æ•æ„Ÿä¿¡æ¯æ‰“ç ï¼‰ï¼Œä»¥è¯æ˜æ•°æ®è§„æ¨¡çš„çœŸå®æ€§ã€‚

<img width="956" height="1066" alt="ScreenShot_2026-01-04_150236_959" src="https://github.com/user-attachments/assets/92c258fb-e6c5-443b-ac01-0ded571c45df" />
<img width="968" height="922" alt="ScreenShot_2026-01-04_150244_350" src="https://github.com/user-attachments/assets/9737c2ef-4544-4428-9ae4-e309b2b33a00" />
<img width="982" height="1072" alt="ScreenShot_2026-01-04_150303_473" src="https://github.com/user-attachments/assets/98544c75-6177-44e6-9621-86aa0a90c13a" />
<img width="1732" height="980" alt="ScreenShot_2026-01-04_150609_931" src="https://github.com/user-attachments/assets/02be5a54-e157-4239-8478-6b6663509758" />
<img width="1124" height="1572" alt="ScreenShot_2026-01-04_150407_043" src="https://github.com/user-attachments/assets/e6830e2f-591e-448e-a99f-a26037a0bc39" />
<img width="1356" height="1322" alt="ScreenShot_2026-01-04_150511_220" src="https://github.com/user-attachments/assets/47e62d0f-5f42-4c2d-8479-62413945ee64" />


### ç›¸å…³æ¨è
* **æ­Œå”±è¯„ä»·ç ”ç©¶ï¼š** å¦‚æœæ‚¨æ­£åœ¨ä»äº‹æ­Œå”±è¯„åˆ†æˆ–ç›¸å…³å·¥ä½œï¼Œæ¬¢è¿å‚è€ƒæˆ‘ä»¬çš„å¦ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼š[**QwenFeat-Vocal-Score**](https://github.com/CarlWangChina/QwenFeat-Vocal-Score)ã€‚
* **å…¶ä»–æ­Œå”±æ•°æ®ï¼š** å¯¹äºå¼€æºçš„æ­Œå”±èµ„æºï¼Œè¯·å…³æ³¨æˆ‘ä»¬çš„å§å¦¹é¡¹ç›® **VocalVerse**ã€‚

---

## ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬ä½œå“æˆ–å‚è€ƒäº†å…¶ä¸­çš„æ¦‚å¿µï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

**ACM Reference Format:**
> Zihao Wang, Shulei Ji, Le Ma, Yuhang Jin, Shun Lei, Jianyi Chen, Haoying Fu, Roger B. Dannenberg, and Kejun Zhang. 2025. Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition. In *Proceedings of the 33rd ACM International Conference on Multimedia (MM '25)*. Association for Computing Machinery, New York, NY, USA, 12714â€“12721. [https://doi.org/10.1145/3746027.3758210](https://doi.org/10.1145/3746027.3758210).

**BibTeX:**

```bibtex
@inproceedings{10.1145/3746027.3758210,
   author = {Wang, Zihao and Ji, Shulei and Ma, Le and Jin, Yuhang and Lei, Shun and Chen, Jianyi and Fu, Haoying and Dannenberg, Roger B. and Zhang, Kejun},
   title = {Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition},
   year = {2025},
   isbn = {9798400720352},
   publisher = {Association for Computing Machinery},
   address = {New York, NY, USA},
   url = {https://doi.org/10.1145/3746027.3758210},
   doi = {10.1145/3746027.3758210},
   booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
   pages = {12714â€“12721},
   numpages = {8},
   keywords = {dry vocals, mandarin singing dataset, regional chinese accents, singing accent recognition},
   location = {Dublin, Ireland},
   series = {MM '25}
}
```
